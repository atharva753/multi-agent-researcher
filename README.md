# Multi-Agent Researcher

## Setup

1. Clone this repo
2. Create a virtual environment:
   ```bash
   python -m venv .venv
   source .venv/bin/activate  # Windows: .venv\Scripts\activate
   ```
3. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```
4. Copy `.env.example` to `.env` and adjust.

## Running

### Start MCP Server
```bash
python mcp_server.py
```
# ğŸ§  Multi-Agent Researcher

An intelligent, modular **Multi-Agent AI Assistant** that performs deep research on user queries using large language models (LLMs). It supports custom use cases like academic summarization, code reviews, startup validation, and document summarization â€” all through a clean Streamlit UI and backend agent orchestration.

---

## ğŸš€ Features

- ğŸ§© **Modular Agents** â€“ Agents for search, summarization, and writing  
- ğŸ“„ **PDF/TXT Uploader** â€“ Upload your own files for instant summarization  
- ğŸ¤– **Model Selector** â€“ Choose from `deepseek-coder`, `mistral`, or `phi3` via Ollama  
- ğŸ¯ **Use Case Picker** â€“ Academic, Code Review, Startup Validator modes  
- ğŸ§  **Tone Control** â€“ Objective, critical, optimistic, balanced, skeptical  
- ğŸ’¬ **Chat History + Export** â€“ Session logs with download as `.md` or `.txt`  
- ğŸŒ **Streamlit Frontend** â€“ Fast, interactive, and local web-based interface  
- âš™ï¸ **FastAPI Backend (MCP Server)** â€“ Modular command endpoint system

---

## ğŸ“ Folder Structure

```
multi-agent-researcher/
â”œâ”€â”€ mcp_server.py             # Starts MCP agent backend
â”œâ”€â”€ streamlit_ui.py           # Frontend interface
â”œâ”€â”€ multi_agents/
â”‚   â””â”€â”€ main.py               # Agent controller functions
â”œâ”€â”€ server/
â”‚   â””â”€â”€ fastmcp.py            # Lightweight FastAPI-based agent orchestration
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env.example
â””â”€â”€ README.md
```

---

## ğŸ› ï¸ Installation & Setup

### 1. Clone the repo
```bash
git clone https://github.com/atharva753/multi-agent-researcher.git
cd multi-agent-researcher
```

### 2. Setup virtual environment
```bash
python -m venv .venv
.\.venv\Scripts ctivate      # On Windows
# OR
source .venv/bin/activate     # On macOS/Linux
```

### 3. Install dependencies
```bash
pip install -r requirements.txt
```

### 4. Configure environment
```bash
cp .env.example .env
```

### 5. Pull model(s) via Ollama
```bash
ollama pull deepseek-coder
ollama pull mistral
ollama pull phi3
```

---

## ğŸ§ª Running the App

### Start the backend (MCP server)
```bash
python mcp_server.py
```

 MCP Server Running
![MCP Server](screenshots/mcp-server.png)  
FastAPIâ€‘based MCP server registering `deep_research` and `summarize_file` tools and listening on port 8000.

### Start the frontend (Streamlit UI)
```bash
streamlit run streamlit_ui.py
```

Go to: [http://localhost:8501](http://localhost:8501)

Streamlit Home Interface
![UI Home](screenshots/ui-home.png)  
Streamlit UI showing the home screen with model selector, tone picker, and use-case dropdown.
---

## ğŸ§  Use Cases

| Mode             | Description                                                                 |
|------------------|-----------------------------------------------------------------------------|
| **Academic**     | Research summaries, paper breakdowns, and fact-based explorations           |
| **Code Review**  | Paste code or upload a `.txt` snippet to get AI insights and improvements   |
| **Startup Validator** | Idea checks, SWOT-style validation, and execution risk summaries       |
| **PDF Summarizer** | Upload a PDF and extract a 1-click agent-generated summary                |

---

## ğŸŒ Deploy Anywhere

### âœ… Streamlit Cloud
1. Push this repo to your GitHub
2. Go to [streamlit.io/cloud](https://streamlit.io/cloud)
3. Link the repo and point to `streamlit_ui.py`
4. Add environment variables if needed (e.g., `OLLAMA_HOST`)

### âœ… Hugging Face Spaces *(if you remove Ollama dependency)*  
1. Replace local models with hosted LLM APIs (OpenAI, Anthropic, Groq, etc.)
2. Deploy `streamlit_ui.py` as an app

---

## ğŸ™‹ Who is This For?

- Students exploring **multi-agent AI workflows**
- Developers building **domain-specific AI assistants**
- Recruiters evaluating **applied AI, LangChain, or Ollama experience**
- Teams experimenting with **RAG pipelines, summarization, or UI agents**

## ğŸ§  Example Use Cases

- **Academic Paper Summarization** â€“ Upload papers and get fast summaries

![PDF Summary](screenshots/ui-pdf-summary.png)  
*Uploading a PDF and clicking â€œSummarize Fileâ€ to get a concise summary of the document content.*


- **Code Review** â€“ Find issues and refactor suggestions in pasted/uploaded code

Code Review Use Case
![Code Review](screenshots/ui-code review.png)  
*Using the Code Review mode with Mistral and Critical tone to analyze and suggest improvements on a snippet of code.*


- **Startup Validator** â€“ Validate your business ideas using agent SWOT analysis
- **Topic Deep-Dives** â€“ Query complex topics (e.g., climate tech) and get multi-agent synthesis

After Running a Research Query
![UI Response](screenshots/ui-response.png)  
*Result of asking â€œWhat are the latest trends in green hydrogen tech?â€ using Mistral with Critical tone, showing chat history and export option.*

- **Policy/Report Summarization** â€“ Drop in PDFs and extract key takeaways instantly


---

## ğŸ§· Badges

![Streamlit](https://img.shields.io/badge/Frontend-Streamlit-orange)
![Backend](https://img.shields.io/badge/Backend-FastAPI-blue)
![Model](https://img.shields.io/badge/Model-Ollama-cc00ff)
![License](https://img.shields.io/badge/License-MIT-green)

---

## ğŸ¤ Contributing

Pull requests welcome! You can:
- Add new agent tools
- Improve the UI
- Add integrations (e.g., real-time web search, vector store, OpenAI tools)

---
### Start Streamlit UI
```bash
streamlit run streamlit_ui.py
```

Open [http://localhost:8501](http://localhost:8501).
